"""
RAGæ£€ç´¢æœåŠ¡ - FAISSç‰ˆæœ¬
æä¾›çŸ¥è¯†åº“æ£€ç´¢å’Œä¸Šä¸‹æ–‡æ„å»ºåŠŸèƒ½
ä½¿ç”¨FAISSä½œä¸ºå‘é‡æ•°æ®åº“ï¼ˆè½»é‡çº§ï¼Œæ˜“å®‰è£…ï¼‰
"""

from pathlib import Path
from functools import lru_cache
import pickle
import json

try:
    from sentence_transformers import SentenceTransformer
    import faiss
    import numpy as np
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False
    print("è­¦å‘Š: RAGä¾èµ–æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼åŠ è½½çŸ¥è¯†åº“")
    print("å®‰è£…æ–¹æ³•: pip install -r requirements_rag.txt")


class RAGService:
    """RAGæ£€ç´¢æœåŠ¡ - FAISSç‰ˆæœ¬"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–RAGæœåŠ¡"""
        if self._initialized:
            return
        
        self.rag_available = RAG_AVAILABLE
        
        if not RAG_AVAILABLE:
            self._initialized = True
            return
        
        try:
            # åˆå§‹åŒ–å‘é‡æ¨¡å‹
            print("åˆå§‹åŒ–RAGæœåŠ¡...")
            self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            
            # åˆå§‹åŒ–FAISSç´¢å¼•
            backend_dir = Path(__file__).parent.parent
            self.db_path = backend_dir / 'vector_db'
            
            # åŠ è½½ç´¢å¼•å’Œå…ƒæ•°æ®
            index_file = self.db_path / 'faiss_index.pkl'
            metadata_file = self.db_path / 'metadata.pkl'
            
            if index_file.exists() and metadata_file.exists():
                with open(index_file, 'rb') as f:
                    index_bytes = pickle.load(f)
                    self.index = faiss.deserialize_index(index_bytes)
                with open(metadata_file, 'rb') as f:
                    self.metadata = pickle.load(f)
                print(f"[OK] RAGæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ŒçŸ¥è¯†åº“åŒ…å« {self.index.ntotal} ä¸ªå—")
            else:
                print(f"[WARNING] çŸ¥è¯†åº“æœªåˆå§‹åŒ–")
                print("è¯·è¿è¡Œ: python scripts/init_rag.py")
                self.index = None
                self.metadata = None
                self.rag_available = False
            
            self._initialized = True
            
        except Exception as e:
            print(f"RAGæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            self.rag_available = False
            self._initialized = True
    
    @lru_cache(maxsize=100)
    def retrieve(self, query: str, top_k: int = 3):
        """
        æ£€ç´¢ç›¸å…³çŸ¥è¯†
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡
            
        Returns:
            ç›¸å…³çŸ¥è¯†åˆ—è¡¨
        """
        if not self.rag_available or self.index is None:
            return {'documents': [[]], 'metadatas': [[]]}
        
        try:
            # å‘é‡åŒ–æŸ¥è¯¢
            query_embedding = self.model.encode([query])
            query_embedding = np.array(query_embedding).astype('float32')
            
            # æ£€ç´¢
            distances, indices = self.index.search(query_embedding, top_k)
            
            # æ ¼å¼åŒ–ç»“æœ
            documents = []
            metadatas = []
            
            for idx in indices[0]:
                if idx < len(self.metadata):
                    meta = self.metadata[idx]
                    documents.append(meta['content'])
                    metadatas.append({
                        'file': meta.get('file', ''),
                        'section': meta.get('section', ''),
                        'priority': meta.get('priority', 3),
                        'tags': meta.get('tags', '')
                    })
            
            return {
                'documents': [documents],
                'metadatas': [metadatas]
            }
            
        except Exception as e:
            print(f"æ£€ç´¢å¤±è´¥: {e}")
            return {'documents': [[]], 'metadatas': [[]]}
    
    def hybrid_retrieve(self, query: str, interaction_type: str, top_k: int = 3):
        """
        æ··åˆæ£€ç´¢ï¼šç»“åˆå‘é‡æ£€ç´¢å’Œè§„åˆ™è¿‡æ»¤
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            interaction_type: äº¤äº’ç±»å‹ï¼ˆintro/like/gift/commentï¼‰
            top_k: è¿”å›æ•°é‡
            
        Returns:
            ç›¸å…³çŸ¥è¯†åˆ—è¡¨
        """
        if not self.rag_available or self.index is None:
            return {'documents': [[]], 'metadatas': [[]]}
        
        try:
            # 1. å‘é‡æ£€ç´¢ï¼ˆå¤šæ£€ç´¢ä¸€äº›ï¼Œç”¨äºåç»­è¿‡æ»¤ï¼‰
            results = self.retrieve(query, top_k * 3)
            
            # 2. è§„åˆ™è¿‡æ»¤
            filtered_docs = []
            filtered_metas = []
            
            for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):
                tags = metadata.get('tags', '').split(',')
                file_name = metadata.get('file', '')
                
                # æ ¹æ®äº¤äº’ç±»å‹è¿‡æ»¤
                should_include = False
                
                if interaction_type == 'auto_intro':
                    # ä»‹ç»åœºæ™¯ï¼šä¼˜å…ˆå¹³å°çŸ¥è¯†å’Œä¸–ç•Œè§‚
                    if any(tag in tags for tag in ['å¹³å°', 'MaxGamer', 'SaaS', 'ä¸–ç•Œè§‚']):
                        should_include = True
                    elif 'platform_knowledge' in file_name or 'worldview' in file_name:
                        should_include = True
                
                elif interaction_type in ['like', 'gift', 'comment']:
                    # äº’åŠ¨åœºæ™¯ï¼šä¼˜å…ˆäº’åŠ¨æŒ‡å—å’Œæ€§æ ¼è®¾å®š
                    if any(tag in tags for tag in ['äº’åŠ¨', 'åœºæ™¯', 'å›å¤', 'æ€§æ ¼']):
                        should_include = True
                    elif 'login_guide' in file_name or 'character_personality' in file_name:
                        should_include = True
                
                # æ•…äº‹å…ƒç´ ï¼ˆå¯é€‰ï¼‰
                if any(tag in tags for tag in ['æ•…äº‹', 'æƒ…ç»ªç†µ', 'è§‚å¯Ÿè€…']):
                    # é™ä½ä¼˜å…ˆçº§ï¼Œä½†ä»ç„¶åŒ…å«
                    metadata['priority'] = int(metadata.get('priority', 3)) + 1
                    should_include = True
                
                if should_include:
                    filtered_docs.append(doc)
                    filtered_metas.append(metadata)
            
            # 3. é‡æ’åºï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
            sorted_pairs = sorted(
                zip(filtered_docs, filtered_metas),
                key=lambda x: x[1].get('priority', 3)
            )
            
            # 4. è¿”å›top_kä¸ªç»“æœ
            if sorted_pairs:
                filtered_docs, filtered_metas = zip(*sorted_pairs[:top_k])
                return {
                    'documents': [list(filtered_docs)],
                    'metadatas': [list(filtered_metas)]
                }
            else:
                return {'documents': [[]], 'metadatas': [[]]}
            
        except Exception as e:
            print(f"æ··åˆæ£€ç´¢å¤±è´¥: {e}")
            return {'documents': [[]], 'metadatas': [[]]}
    
    def build_context(self, query: str, interaction_type: str):
        """
        æ„å»ºLLMä¸Šä¸‹æ–‡
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            interaction_type: äº¤äº’ç±»å‹
            
        Returns:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
        """
        # 1. åŸºç¡€è§’è‰²è®¾å®šï¼ˆæ€»æ˜¯åŒ…å«ï¼‰
        base_prompt = self._load_base_prompt()
        
        # 2. æ£€ç´¢ç›¸å…³çŸ¥è¯†
        if self.rag_available and self.index is not None:
            results = self.hybrid_retrieve(query, interaction_type, top_k=3)
            
            if results['documents'][0]:
                # æ„å»ºçŸ¥è¯†ä¸Šä¸‹æ–‡
                context_parts = []
                for doc, meta in zip(results['documents'][0], results['metadatas'][0]):
                    section = meta.get('section', 'æœªçŸ¥ç« èŠ‚')
                    context_parts.append(f"## {section}\n\n{doc}")
                
                context = "\n\n---\n\n".join(context_parts)
                
                system_prompt = f"""{base_prompt}

## ç›¸å…³çŸ¥è¯†å‚è€ƒ

{context}

è¯·æ ¹æ®ä»¥ä¸Šè§’è‰²è®¾å®šå’Œç›¸å…³çŸ¥è¯†ï¼Œä»¥Maxçš„èº«ä»½å›å¤ç”¨æˆ·ã€‚ä¿æŒç®€çŸ­ï¼ˆ1-2å¥è¯ï¼‰ï¼Œä½¿ç”¨é€‚å½“çš„emojiã€‚
"""
            else:
                system_prompt = base_prompt
        else:
            # RAGä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
            system_prompt = self._load_full_knowledge()
        
        return system_prompt
    
    def _load_base_prompt(self):
        """åŠ è½½åŸºç¡€è§’è‰²è®¾å®š"""
        try:
            backend_dir = Path(__file__).parent.parent
            character_file = backend_dir / 'knowledge_base' / 'max' / 'character.md'
            
            with open(character_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # åªå–å‰é¢çš„å¿«é€Ÿå‚è€ƒéƒ¨åˆ†
                lines = content.split('\n')
                base_lines = []
                for line in lines:
                    base_lines.append(line)
                    if '## ğŸ’¬ å¿«é€Ÿå›å¤æ¨¡æ¿' in line:
                        # è¯»å–åˆ°å¿«é€Ÿå›å¤æ¨¡æ¿åå†è¯»50è¡Œ
                        base_lines.extend(lines[len(base_lines):len(base_lines)+50])
                        break
                
                return '\n'.join(base_lines)
        except Exception as e:
            print(f"åŠ è½½åŸºç¡€æç¤ºè¯å¤±è´¥: {e}")
            return "ä½ æ˜¯Maxï¼ŒMaxGamerå¹³å°çš„AIåŠ©æ‰‹ã€‚"
    
    def _load_full_knowledge(self):
        """åŠ è½½å®Œæ•´çŸ¥è¯†åº“ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰"""
        try:
            backend_dir = Path(__file__).parent.parent
            knowledge_dir = backend_dir / 'knowledge_base' / 'max'
            
            files = [
                'character.md',
                'character_personality.md',
                'platform_knowledge.md',
                'login_guide.md'
            ]
            
            knowledge_parts = []
            for file_name in files:
                file_path = knowledge_dir / file_name
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        knowledge_parts.append(f.read())
            
            return '\n\n---\n\n'.join(knowledge_parts)
            
        except Exception as e:
            print(f"åŠ è½½å®Œæ•´çŸ¥è¯†åº“å¤±è´¥: {e}")
            return "ä½ æ˜¯Maxï¼ŒMaxGamerå¹³å°çš„AIåŠ©æ‰‹ã€‚"
    
    def get_stats(self):
        """è·å–RAGæœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        if not self.rag_available or self.index is None:
            return {
                'available': False,
                'reason': 'RAGæœåŠ¡æœªåˆå§‹åŒ–æˆ–ä¾èµ–æœªå®‰è£…'
            }
        
        try:
            return {
                'available': True,
                'total_chunks': self.index.ntotal,
                'cache_size': self.retrieve.cache_info().currsize,
                'cache_hits': self.retrieve.cache_info().hits,
                'cache_misses': self.retrieve.cache_info().misses
            }
        except Exception as e:
            return {
                'available': False,
                'error': str(e)
            }


# åˆ›å»ºå…¨å±€å®ä¾‹
rag_service = RAGService()