"""
RAGæ£€ç´¢æœåŠ¡
æä¾›çŸ¥è¯†åº“æ£€ç´¢å’Œä¸Šä¸‹æ–‡æ„å»ºåŠŸèƒ½
"""

from pathlib import Path
from functools import lru_cache
import hashlib

try:
    from sentence_transformers import SentenceTransformer
    import chromadb
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False
    print("è­¦å‘Š: RAGä¾èµ–æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼åŠ è½½çŸ¥è¯†åº“")
    print("å®‰è£…æ–¹æ³•: pip install chromadb sentence-transformers")


class RAGService:
    """RAGæ£€ç´¢æœåŠ¡"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–RAGæœåŠ¡"""
        if self._initialized:
            return
        
        self.rag_available = RAG_AVAILABLE
        
        if not RAG_AVAILABLE:
            self._initialized = True
            return
        
        try:
            # åˆå§‹åŒ–å‘é‡æ¨¡å‹
            print("åˆå§‹åŒ–RAGæœåŠ¡...")
            self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            
            # åˆå§‹åŒ–ChromaDB
            backend_dir = Path(__file__).parent.parent
            db_path = backend_dir / 'chroma_db'
            
            self.client = chromadb.PersistentClient(path=str(db_path))
            
            # è·å–é›†åˆ
            try:
                self.collection = self.client.get_collection(name="max_knowledge")
                print(f"âœ“ RAGæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ŒçŸ¥è¯†åº“åŒ…å« {self.collection.count()} ä¸ªå—")
            except Exception as e:
                print(f"è­¦å‘Š: çŸ¥è¯†åº“æœªåˆå§‹åŒ– - {e}")
                print("è¯·è¿è¡Œ: python scripts/init_rag.py")
                self.collection = None
                self.rag_available = False
            
            self._initialized = True
            
        except Exception as e:
            print(f"RAGæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            self.rag_available = False
            self._initialized = True
    
    @lru_cache(maxsize=100)
    def retrieve(self, query, top_k=3):
        """
        æ£€ç´¢ç›¸å…³çŸ¥è¯†
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡
            
        Returns:
            ç›¸å…³çŸ¥è¯†åˆ—è¡¨
        """
        if not self.rag_available or self.collection is None:
            return []
        
        try:
            # å‘é‡åŒ–æŸ¥è¯¢
            query_embedding = self.model.encode(query)
            
            # æ£€ç´¢
            results = self.collection.query(
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            knowledge_chunks = []
            for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):
                knowledge_chunks.append({
                    'content': doc,
                    'file': metadata.get('file', ''),
                    'section': metadata.get('section', ''),
                    'priority': metadata.get('priority', 3),
                    'tags': metadata.get('tags', '').split(',')
                })
            
            return knowledge_chunks
            
        except Exception as e:
            print(f"æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def hybrid_retrieve(self, query, interaction_type, top_k=3):
        """
        æ··åˆæ£€ç´¢ï¼šç»“åˆå‘é‡æ£€ç´¢å’Œè§„åˆ™è¿‡æ»¤
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            interaction_type: äº¤äº’ç±»å‹ï¼ˆintro/like/gift/commentï¼‰
            top_k: è¿”å›æ•°é‡
            
        Returns:
            ç›¸å…³çŸ¥è¯†åˆ—è¡¨
        """
        if not self.rag_available or self.collection is None:
            return []
        
        try:
            # 1. å‘é‡æ£€ç´¢ï¼ˆå¤šæ£€ç´¢ä¸€äº›ï¼Œç”¨äºåç»­è¿‡æ»¤ï¼‰
            query_embedding = self.model.encode(query)
            
            results = self.collection.query(
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k * 3  # æ£€ç´¢3å€æ•°é‡ç”¨äºè¿‡æ»¤
            )
            
            # 2. è§„åˆ™è¿‡æ»¤
            filtered_results = []
            
            for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):
                tags = metadata.get('tags', '').split(',')
                file_name = metadata.get('file', '')
                
                # æ ¹æ®äº¤äº’ç±»å‹è¿‡æ»¤
                should_include = False
                
                if interaction_type == 'intro':
                    # ä»‹ç»åœºæ™¯ï¼šä¼˜å…ˆå¹³å°çŸ¥è¯†å’Œä¸–ç•Œè§‚
                    if any(tag in tags for tag in ['å¹³å°', 'MaxGamer', 'SaaS', 'ä¸–ç•Œè§‚']):
                        should_include = True
                    elif 'platform_knowledge' in file_name or 'worldview' in file_name:
                        should_include = True
                
                elif interaction_type in ['like', 'gift', 'comment']:
                    # äº’åŠ¨åœºæ™¯ï¼šä¼˜å…ˆäº’åŠ¨æŒ‡å—å’Œæ€§æ ¼è®¾å®š
                    if any(tag in tags for tag in ['äº’åŠ¨', 'åœºæ™¯', 'å›å¤', 'æ€§æ ¼']):
                        should_include = True
                    elif 'login_guide' in file_name or 'character_personality' in file_name:
                        should_include = True
                
                # æ•…äº‹å…ƒç´ ï¼ˆå¯é€‰ï¼‰
                if any(tag in tags for tag in ['æ•…äº‹', 'æƒ…ç»ªç†µ', 'è§‚å¯Ÿè€…']):
                    # é™ä½ä¼˜å…ˆçº§ï¼Œä½†ä»ç„¶åŒ…å«
                    metadata['priority'] = int(metadata.get('priority', 3)) + 1
                    should_include = True
                
                if should_include:
                    filtered_results.append({
                        'content': doc,
                        'file': metadata.get('file', ''),
                        'section': metadata.get('section', ''),
                        'priority': int(metadata.get('priority', 3)),
                        'tags': tags
                    })
            
            # 3. é‡æ’åºï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
            filtered_results.sort(key=lambda x: x['priority'])
            
            # 4. è¿”å›top_kä¸ªç»“æœ
            return filtered_results[:top_k]
            
        except Exception as e:
            print(f"æ··åˆæ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def build_context(self, query, interaction_type):
        """
        æ„å»ºLLMä¸Šä¸‹æ–‡
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            interaction_type: äº¤äº’ç±»å‹
            
        Returns:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
        """
        # 1. åŸºç¡€è§’è‰²è®¾å®šï¼ˆæ€»æ˜¯åŒ…å«ï¼‰
        base_prompt = self._load_base_prompt()
        
        # 2. æ£€ç´¢ç›¸å…³çŸ¥è¯†
        if self.rag_available and self.collection is not None:
            relevant_knowledge = self.hybrid_retrieve(query, interaction_type, top_k=3)
            
            if relevant_knowledge:
                # æ„å»ºçŸ¥è¯†ä¸Šä¸‹æ–‡
                context_parts = []
                for chunk in relevant_knowledge:
                    context_parts.append(f"## {chunk['section']}\n\n{chunk['content']}")
                
                context = "\n\n---\n\n".join(context_parts)
                
                system_prompt = f"""{base_prompt}

## ç›¸å…³çŸ¥è¯†å‚è€ƒ

{context}

è¯·æ ¹æ®ä»¥ä¸Šè§’è‰²è®¾å®šå’Œç›¸å…³çŸ¥è¯†ï¼Œä»¥Maxçš„èº«ä»½å›å¤ç”¨æˆ·ã€‚ä¿æŒç®€çŸ­ï¼ˆ1-2å¥è¯ï¼‰ï¼Œä½¿ç”¨é€‚å½“çš„emojiã€‚
"""
            else:
                system_prompt = base_prompt
        else:
            # RAGä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
            system_prompt = self._load_full_knowledge()
        
        return system_prompt
    
    def _load_base_prompt(self):
        """åŠ è½½åŸºç¡€è§’è‰²è®¾å®š"""
        try:
            backend_dir = Path(__file__).parent.parent
            character_file = backend_dir / 'knowledge_base' / 'max' / 'character.md'
            
            with open(character_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # åªå–å‰é¢çš„å¿«é€Ÿå‚è€ƒéƒ¨åˆ†
                lines = content.split('\n')
                base_lines = []
                for line in lines:
                    base_lines.append(line)
                    if '## ğŸ’¬ å¿«é€Ÿå›å¤æ¨¡æ¿' in line:
                        # è¯»å–åˆ°å¿«é€Ÿå›å¤æ¨¡æ¿åå†è¯»50è¡Œ
                        base_lines.extend(lines[len(base_lines):len(base_lines)+50])
                        break
                
                return '\n'.join(base_lines)
        except Exception as e:
            print(f"åŠ è½½åŸºç¡€æç¤ºè¯å¤±è´¥: {e}")
            return "ä½ æ˜¯Maxï¼ŒMaxGamerå¹³å°çš„AIåŠ©æ‰‹ã€‚"
    
    def _load_full_knowledge(self):
        """åŠ è½½å®Œæ•´çŸ¥è¯†åº“ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰"""
        try:
            backend_dir = Path(__file__).parent.parent
            knowledge_dir = backend_dir / 'knowledge_base' / 'max'
            
            files = [
                'character.md',
                'character_personality.md',
                'platform_knowledge.md',
                'login_guide.md'
            ]
            
            knowledge_parts = []
            for file_name in files:
                file_path = knowledge_dir / file_name
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        knowledge_parts.append(f.read())
            
            return '\n\n---\n\n'.join(knowledge_parts)
            
        except Exception as e:
            print(f"åŠ è½½å®Œæ•´çŸ¥è¯†åº“å¤±è´¥: {e}")
            return "ä½ æ˜¯Maxï¼ŒMaxGamerå¹³å°çš„AIåŠ©æ‰‹ã€‚"
    
    def get_stats(self):
        """è·å–RAGæœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        if not self.rag_available or self.collection is None:
            return {
                'available': False,
                'reason': 'RAGæœåŠ¡æœªåˆå§‹åŒ–æˆ–ä¾èµ–æœªå®‰è£…'
            }
        
        try:
            count = self.collection.count()
            return {
                'available': True,
                'total_chunks': count,
                'cache_size': self.retrieve.cache_info().currsize,
                'cache_hits': self.retrieve.cache_info().hits,
                'cache_misses': self.retrieve.cache_info().misses
            }
        except Exception as e:
            return {
                'available': False,
                'error': str(e)
            }


# åˆ›å»ºå…¨å±€å®ä¾‹
rag_service = RAGService()