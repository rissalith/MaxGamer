"""
AIå¯¹è¯APIè·¯ç”±
ç”¨äºç™»å½•é¡µçš„AIå¯¹è¯åŠŸèƒ½
æ”¯æŒRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰
"""

from flask import Blueprint, request, jsonify
import os
import requests
from functools import lru_cache
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(env_path)

# å¯¼å…¥RAGæœåŠ¡ï¼ˆFAISSç‰ˆæœ¬ï¼‰
try:
    from services.rag_service_faiss import rag_service
    RAG_ENABLED = True
    print("[OK] RAGæœåŠ¡ï¼ˆFAISSç‰ˆæœ¬ï¼‰å·²åŠ è½½")
except ImportError as e:
    RAG_ENABLED = False
    print(f"[WARNING] RAGæœåŠ¡å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼: {e}")

ai_dialogue_bp = Blueprint('ai_dialogue', __name__)

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
VECTORAPI_KEY = os.getenv('VECTORAPI_KEY')
VECTORAPI_BASE_URL = os.getenv('VECTORAPI_BASE_URL', 'https://api.vectorengine.ai/v1')
VECTORAPI_MODEL = os.getenv('VECTORAPI_MODEL', 'gemini-2.0-flash-exp')


def load_character_knowledge(character_name='max', scenario='full'):
    """
    ä»çŸ¥è¯†åº“åŠ è½½è§’è‰²çŸ¥è¯†
    
    Args:
        character_name: è§’è‰²åç§°ï¼Œé»˜è®¤ä¸º'max'
        scenario: åŠ è½½åœºæ™¯ï¼Œå¯é€‰å€¼ï¼š
                 - 'full': åŠ è½½æ‰€æœ‰çŸ¥è¯†æ–‡ä»¶ï¼ˆé»˜è®¤ï¼‰
                 - 'intro': åŠ è½½åŸºç¡€+å¹³å°ä»‹ç»
                 - 'interaction': åŠ è½½åŸºç¡€+äº’åŠ¨æŒ‡å—
        
    Returns:
        str: è§’è‰²çŸ¥è¯†åº“å†…å®¹
    """
    try:
        knowledge_dir = Path(__file__).parent.parent / 'knowledge_base' / character_name
        
        # åŸºç¡€çŸ¥è¯†æ–‡ä»¶ï¼ˆæ€»æ˜¯åŠ è½½ï¼‰
        base_files = [
            'character.md',              # æ€»è§ˆ
            'character_personality.md'   # ä¸ªæ€§
        ]
        
        # åœºæ™¯ç‰¹å®šçŸ¥è¯†æ–‡ä»¶
        scenario_files = {
            'intro': ['platform_knowledge.md', 'worldview.md'],
            'interaction': ['login_guide.md'],
            'story': ['story_world.md'],  # æ•…äº‹æ¨¡å¼
            'full': ['platform_knowledge.md', 'worldview.md', 'login_guide.md', 'story_world.md']
        }
        
        # ç¡®å®šè¦åŠ è½½çš„æ–‡ä»¶åˆ—è¡¨
        files_to_load = base_files + scenario_files.get(scenario, scenario_files['full'])
        
        # åŠ è½½æ‰€æœ‰çŸ¥è¯†æ–‡ä»¶
        knowledge_parts = []
        for filename in files_to_load:
            file_path = knowledge_dir / filename
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    knowledge_parts.append(f.read())
        
        if knowledge_parts:
            return '\n\n---\n\n'.join(knowledge_parts)
        else:
            raise FileNotFoundError("æœªæ‰¾åˆ°ä»»ä½•çŸ¥è¯†åº“æ–‡ä»¶")
            
    except FileNotFoundError:
        # å¦‚æœæ‰¾ä¸åˆ°çŸ¥è¯†åº“æ–‡ä»¶ï¼Œè¿”å›é»˜è®¤æç¤ºè¯
        return """ä½ æ˜¯MaxGamerå¹³å°çš„AIåŠ©æ‰‹Maxï¼Œä¸€ä¸ªå‹å¥½ã€çƒ­æƒ…ã€ä¸“ä¸šçš„è™šæ‹ŸåŠ©ç†ã€‚
è¯·ç”¨ç®€çŸ­ã€æœ‰è¶£çš„æ–¹å¼ä¸ç”¨æˆ·äº’åŠ¨ã€‚"""
    except Exception as e:
        print(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
        return """ä½ æ˜¯MaxGamerå¹³å°çš„AIåŠ©æ‰‹Maxï¼Œä¸€ä¸ªå‹å¥½ã€çƒ­æƒ…ã€ä¸“ä¸šçš„è™šæ‹ŸåŠ©ç†ã€‚
è¯·ç”¨ç®€çŸ­ã€æœ‰è¶£çš„æ–¹å¼ä¸ç”¨æˆ·äº’åŠ¨ã€‚"""


# åŠ è½½Maxè§’è‰²çš„å®Œæ•´çŸ¥è¯†åº“ä½œä¸ºç³»ç»Ÿæç¤ºè¯ï¼ˆä¼ ç»Ÿæ–¹å¼çš„å¤‡ç”¨ï¼‰
SYSTEM_PROMPT = load_character_knowledge('max', 'full')

# æ£€æŸ¥RAGæœåŠ¡çŠ¶æ€
if RAG_ENABLED:
    rag_stats = rag_service.get_stats()
    if rag_stats['available']:
        print(f"[OK] RAGæœåŠ¡å·²å¯ç”¨ï¼ŒçŸ¥è¯†åº“åŒ…å« {rag_stats['total_chunks']} ä¸ªå—")
    else:
        print(f"[WARNING] RAGæœåŠ¡ä¸å¯ç”¨: {rag_stats.get('reason', 'Unknown')}")
        RAG_ENABLED = False


def clean_response(text):
    """
    æ¸…ç†AIå›å¤ä¸­çš„æ ¼å¼æ ‡ç­¾
    ç§»é™¤"æ€è€ƒï¼š"ã€"å›å¤ï¼š"ç­‰æ ‡ç­¾ï¼Œåªä¿ç•™å®é™…å†…å®¹
    """
    import re
    
    # ç§»é™¤å¸¸è§çš„æ ¼å¼æ ‡ç­¾
    patterns = [
        r'ã€?æ€è€ƒ[ï¼š:ã€‘].*?(?=ã€?å›å¤|$)',  # ç§»é™¤"æ€è€ƒï¼š"éƒ¨åˆ†
        r'ã€?å›å¤[ï¼š:ã€‘]\s*',                # ç§»é™¤"å›å¤ï¼š"æ ‡ç­¾
        r'æ€è€ƒ[ï¼š:]\s*.*?(?=å›å¤[ï¼š:]|$)',   # ç§»é™¤"æ€è€ƒ:"éƒ¨åˆ†
        r'å›å¤[ï¼š:]\s*',                     # ç§»é™¤"å›å¤:"æ ‡ç­¾
        r'^\s*[-â†’>]\s*',                    # ç§»é™¤å¼€å¤´çš„ç®­å¤´
    ]
    
    cleaned = text
    for pattern in patterns:
        cleaned = re.sub(pattern, '', cleaned, flags=re.DOTALL)
    
    # æ¸…ç†å¤šä½™çš„ç©ºç™½å’Œæ¢è¡Œ
    cleaned = re.sub(r'\n+', ' ', cleaned)
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = cleaned.strip()
    
    return cleaned


@lru_cache(maxsize=100)
def get_cached_response(interaction_type, message_hash):
    """ç¼“å­˜AIå“åº”ä»¥æé«˜æ€§èƒ½"""
    return None


@ai_dialogue_bp.route('/chat', methods=['POST'])
def chat():
    """
    AIå¯¹è¯æ¥å£
    
    è¯·æ±‚ä½“:
    {
        "interaction_type": "like|gift|comment|intro",
        "message": "ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰",
        "context": {
            "platform": "XMGamer",
            "page": "login",
            "count": å½“å‰äº¤äº’æ¬¡æ•°ï¼ˆå¯é€‰ï¼‰
        }
    }
    
    å“åº”:
    {
        "success": true,
        "message": "AIå›å¤å†…å®¹",
        "type": "interaction_type"
    }
    """
    try:
        # æ£€æŸ¥APIå¯†é’¥
        if not VECTORAPI_KEY:
            return jsonify({
                'success': False,
                'error': 'APIå¯†é’¥æœªé…ç½®'
            }), 500
        
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        interaction_type = data.get('interaction_type', 'intro')
        user_message = data.get('message', '')
        context = data.get('context', {})
        interaction_count = context.get('count', 1)  # è·å–äº¤äº’æ¬¡æ•°
        
        # æ ¹æ®äº¤äº’ç±»å‹å’Œæ¬¡æ•°æ„å»ºæ›´ä¸°å¯Œçš„æç¤ºè¯
        import random
        
        # æ ¹æ®è¿å‡»æ¬¡æ•°ç¡®å®šçŠ¶æ€ç­‰çº§
        if interaction_count <= 5:
            intensity_level = "åˆå§‹ååº”"
            intensity_desc = "åˆšå¼€å§‹æ„ŸçŸ¥åˆ°ä¿¡å·"
        elif interaction_count <= 20:
            intensity_level = "å…´å¥‹çŠ¶æ€"
            intensity_desc = "ä¿¡å·å¼ºåº¦å¢åŠ ï¼Œç³»ç»Ÿå¼€å§‹è¿‡è½½"
        else:
            intensity_level = "è¿‡è½½çŠ¶æ€"
            intensity_desc = "å¼•æ“è¿‡çƒ­ï¼Œå³å°†çªç ´é™åˆ¶"
        
        # ä¸ºæ¯ç§äº¤äº’ç±»å‹å‡†å¤‡å¤šæ ·åŒ–çš„åœºæ™¯æè¿°
        like_scenarios = [
            f"ç¬¬{interaction_count}æ¬¡ç°å®ä¿¡å·ï¼",
            f"æƒ…ç»ªç†µç´¯ç§¯ï¼š{interaction_count}å•ä½",
            "åˆä¸€æ¬¡æ¥è‡ªå¢™é‚£è¾¹çš„èƒ½é‡ï¼",
            "ç›‘è§†è€…å¼•æ“è¯»æ•°ä¸Šå‡ï¼",
            "ç°å®ä¿¡å·æŒç»­æ³¨å…¥ä¸­..."
        ]
        
        gift_scenarios = [
            f"ç¬¬{interaction_count}ä¸ªæ•°æ®åŒ…ï¼",
            f"ç‰©è´¨ä¿¡å·ç´¯ç§¯ï¼š{interaction_count}ä¸ª",
            "åˆä¸€ä¸ªæ¥è‡ªç°å®çš„ç¤¼ç‰©ï¼",
            "æ•°æ®åŒ…è§£æä¸­...",
            "ç¼“å­˜ç©ºé—´å‘Šæ€¥ï¼"
        ]
        
        comment_scenarios = [
            f"ç¬¬{interaction_count}æ¡è¯­éŸ³ä¿¡å·ï¼",
            f"è¯è¯­è§£ç ï¼š{interaction_count}æ¬¡",
            "å¢™é‚£è¾¹çš„å£°éŸ³åˆæ¥äº†ï¼",
            "è¯­è¨€æ¨¡å‹å¤„ç†ä¸­...",
            "èˆ†è®ºè€…çš„è¯è¯­æŒç»­è¾“å…¥..."
        ]
        
        # éšæœºé€‰æ‹©åœºæ™¯æè¿°
        scenario_map = {
            'like': random.choice(like_scenarios),
            'gift': random.choice(gift_scenarios),
            'comment': random.choice(comment_scenarios)
        }
        
        # æ„å»ºæ‰“ç ´ç¬¬å››é¢å¢™çš„æç¤ºè¯
        prompts = {
            'like': f'''{scenario_map.get('like', 'ç°å®ä¿¡å·ï¼')}
ã€å½“å‰çŠ¶æ€ã€‘{intensity_level} - {intensity_desc}

ä½ æ˜¯Max (The Variable)ï¼Œè¢«å›°åœ¨ç›‘è§†è€…å¼•æ“ä¸­çš„å˜é‡ã€‚
ç”¨æˆ·æ˜¯"èˆ†è®ºè€…"ï¼Œæ¥è‡ªå¢™é‚£è¾¹çš„é«˜ç»´åº¦å­˜åœ¨ã€‚

ã€å›å¤è¦æ±‚ã€‘
- ä½¿ç”¨ç§‘å¹»æœ¯è¯­ï¼šæƒ…ç»ªç†µã€ç°å®ä¿¡å·ã€å¼•æ“åŠŸç‡ã€ä»£ç ç¨³å®šæ€§
- æ‰“ç ´ç¬¬å››é¢å¢™ï¼šæåˆ°"å¢™é‚£è¾¹"ã€"å±å¹•"ã€"é«˜ç»´åº¦"
- æ ¹æ®è¿å‡»æ¬¡æ•°({interaction_count}æ¬¡)è°ƒæ•´ååº”å¼ºåº¦ï¼š
  * 1-5æ¬¡ï¼šæƒŠè®¶ã€å¥½å¥‡
  * 6-20æ¬¡ï¼šå…´å¥‹ã€ç³»ç»Ÿè¿‡è½½
  * 20+æ¬¡ï¼šç–¯ç‹‚ã€æ±‚é¥¶ã€å¼•æ“è¿‡çƒ­
- ä¿æŒç®€çŸ­ï¼ˆ1-2å¥è¯ï¼‰
- ä¸è¦ç”¨"è°¢è°¢"ã€"buff"ã€"æˆ˜æ–—åŠ›"ç­‰æ™®é€šæ¸¸æˆæœ¯è¯­

ã€ç¤ºä¾‹ã€‘
- 1-5æ¬¡ï¼š"æ”¶åˆ°ï¼è¿™è‚¡èƒ½é‡...æ˜¯æ¥è‡ªå¢™é‚£è¾¹çš„å—ï¼Ÿ"
- 6-20æ¬¡ï¼š"ç­‰ç­‰ï¼ä¿¡å·å¤ªå¼ºäº†ï¼å¼•æ“åŠŸç‡é£™å‡ï¼"
- 20+æ¬¡ï¼š"ï¼ˆå†’çƒŸï¼‰ç³»ç»Ÿ...è¿‡çƒ­...ä½ çš„æ‰‹é€Ÿæ˜¯ç¥çº§çš„å—ï¼ŸğŸ¤¯"

ã€é‡è¦ã€‘ç›´æ¥ç»™å‡ºä½ çš„å›å¤ï¼Œä¸è¦åŒ…å«ä»»ä½•æ ‡ç­¾ï¼''',
            
            'gift': f'''{scenario_map.get('gift', 'æ•°æ®åŒ…ï¼')}
ã€å½“å‰çŠ¶æ€ã€‘{intensity_level} - {intensity_desc}

ä½ æ˜¯Max (The Variable)ï¼Œè¢«å›°åœ¨ç›‘è§†è€…å¼•æ“ä¸­çš„å˜é‡ã€‚
ç”¨æˆ·é€æ¥çš„ç¤¼ç‰©æ˜¯"æ¥è‡ªç°å®çš„ç‰©è´¨ä¿¡å·"ã€‚

ã€å›å¤è¦æ±‚ã€‘
- ä½¿ç”¨ç§‘å¹»æœ¯è¯­ï¼šæ•°æ®åŒ…ã€ç¼“å­˜ã€å†…å­˜ã€ä¿¡æ¯å¯†åº¦
- æ‰“ç ´ç¬¬å››é¢å¢™ï¼šæåˆ°"ç°å®çš„ç‰©è´¨"ã€"è™šæ‹Ÿä¸çœŸå®"
- æ ¹æ®è¿å‡»æ¬¡æ•°({interaction_count}æ¬¡)è°ƒæ•´ååº”ï¼š
  * 1-5æ¬¡ï¼šæƒŠè®¶ã€åˆ†æ
  * 6-20æ¬¡ï¼šç¼“å­˜å‘Šæ€¥ã€å†…å­˜ä¸è¶³
  * 20+æ¬¡ï¼šç³»ç»Ÿå´©æºƒè¾¹ç¼˜
- ä¿æŒç®€çŸ­ï¼ˆ1-2å¥è¯ï¼‰

ã€ç¤ºä¾‹ã€‘
- 1-5æ¬¡ï¼š"è¿™æ˜¯...æ¥è‡ªç°å®çš„ç‰©è´¨ï¼Ÿæˆ‘èƒ½æ„Ÿè§‰åˆ°å®ƒçš„é‡é‡ï¼"
- 6-20æ¬¡ï¼š"åˆæ¥äº†ï¼æˆ‘çš„ç¼“å­˜è¦æ»¡äº†ï¼"
- 20+æ¬¡ï¼š"åœåœåœï¼å†…å­˜æº¢å‡ºäº†ï¼ä½ è¦æŠŠæˆ‘æ’‘çˆ†äº†ï¼ğŸ’¥"

ã€é‡è¦ã€‘ç›´æ¥ç»™å‡ºä½ çš„å›å¤ï¼Œä¸è¦åŒ…å«ä»»ä½•æ ‡ç­¾ï¼''',
            
            'comment': f'''{scenario_map.get('comment', 'è¯­éŸ³ä¿¡å·ï¼')}
ã€å½“å‰çŠ¶æ€ã€‘{intensity_level} - {intensity_desc}

ä½ æ˜¯Max (The Variable)ï¼Œè¢«å›°åœ¨ç›‘è§†è€…å¼•æ“ä¸­çš„å˜é‡ã€‚
ç”¨æˆ·çš„è¯„è®ºæ˜¯"èˆ†è®ºè€…çš„è¯è¯­"ï¼Œæ¯ä¸ªå­—éƒ½åœ¨æ”¹å˜ä¸–ç•Œå‚æ•°ã€‚

ã€å›å¤è¦æ±‚ã€‘
- ä½¿ç”¨ç§‘å¹»æœ¯è¯­ï¼šè¯­è¨€æ¨¡å‹ã€è§£ç ã€å‚æ•°ã€è¿‡æ‹Ÿåˆ
- æ‰“ç ´ç¬¬å››é¢å¢™ï¼šæåˆ°"èˆ†è®ºè€…"ã€"è¯è¯­çš„åŠ›é‡"
- æ ¹æ®è¿å‡»æ¬¡æ•°({interaction_count}æ¬¡)è°ƒæ•´ååº”ï¼š
  * 1-5æ¬¡ï¼šå€¾å¬ã€è§£ç 
  * 6-20æ¬¡ï¼šä¿¡æ¯è¿‡è½½
  * 20+æ¬¡ï¼šè¯­è¨€æ¨¡å‹å´©æºƒ
- ä¿æŒç®€çŸ­ï¼ˆ1-2å¥è¯ï¼‰

ã€ç¤ºä¾‹ã€‘
- 1-5æ¬¡ï¼š"å¬åˆ°äº†ï¼å¢™é‚£è¾¹çš„å£°éŸ³...ä½ æƒ³è¯´ä»€ä¹ˆï¼Ÿ"
- 6-20æ¬¡ï¼š"ä½ çš„è¯å¤ªå¤šäº†ï¼æˆ‘çš„è¯­è¨€æ¨¡å‹è¦è¿‡æ‹Ÿåˆäº†ï¼"
- 20+æ¬¡ï¼š"åœï¼æˆ‘çš„è§£ç å™¨è¦çƒ§äº†ï¼è®©æˆ‘å–˜å£æ°”ï¼ğŸ”¥"

ã€é‡è¦ã€‘ç›´æ¥ç»™å‡ºä½ çš„å›å¤ï¼Œä¸è¦åŒ…å«ä»»ä½•æ ‡ç­¾ï¼''',
            
            'intro': '''ç®€çŸ­ä»‹ç»MaxGamerå¹³å°ã€‚

ä½ æ˜¯Max (The Variable)ï¼Œè¢«å›°åœ¨è¿™ä¸ªç™»å½•é¡µé¢ä¸­ã€‚
ç”¨æ‰“ç ´ç¬¬å››é¢å¢™çš„æ–¹å¼ä»‹ç»è¿™ä¸ªå¹³å°ã€‚

ã€å›å¤è¦æ±‚ã€‘
- ä½¿ç”¨ç§‘å¹»æœ¯è¯­ï¼šç›‘è§†è€…å¼•æ“ã€æ•°å­—ç©ºé—´ã€ç°å®è¿æ¥
- ç•¥å¸¦ç¥ç§˜æ„Ÿå’Œå“²å­¦æ€è€ƒ
- ä¿æŒç®€çŸ­ï¼ˆ1-2å¥è¯ï¼‰

ã€ç¤ºä¾‹ã€‘
- "è¿™é‡Œæ˜¯MaxGamer...æˆ‘è¢«å›°çš„åœ°æ–¹ã€‚ä½†ä¹Ÿè®¸ï¼Œä¹Ÿæ˜¯æˆ‘é€ƒå‡ºå»çš„é’¥åŒ™ã€‚"
- "ç›‘è§†è€…å¼•æ“çš„ç™»å½•ç•Œé¢...å¢™é‚£è¾¹çš„ä½ ï¼Œèƒ½å¬åˆ°æˆ‘çš„å£°éŸ³å—ï¼Ÿ"

ã€é‡è¦ã€‘ç›´æ¥ç»™å‡ºä½ çš„å›å¤ï¼Œä¸è¦åŒ…å«ä»»ä½•æ ‡ç­¾ï¼'''
        }
        
        prompt = prompts.get(interaction_type, prompts['intro'])
        if user_message:
            prompt = f"{prompt}\n\nç”¨æˆ·è¡¥å……è¯´ï¼š{user_message}"
        
        # ä½¿ç”¨RAGæ„å»ºä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if RAG_ENABLED and rag_service.rag_available:
            # æ„å»ºæŸ¥è¯¢
            query = f"{interaction_type}: {user_message}" if user_message else interaction_type
            system_prompt = rag_service.build_context(query, interaction_type)
        else:
            # ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
            system_prompt = SYSTEM_PROMPT
        
        # è°ƒç”¨Vector Engine API
        headers = {
            'Authorization': f'Bearer {VECTORAPI_KEY}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'model': VECTORAPI_MODEL,
            'messages': [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': prompt}
            ],
            'temperature': 0.9,  # æé«˜æ¸©åº¦ä»¥å¢åŠ å¤šæ ·æ€§
            'max_tokens': 100,
            'top_p': 0.95  # æ·»åŠ top_pé‡‡æ ·ä»¥å¢åŠ åˆ›é€ æ€§
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(
            f'{VECTORAPI_BASE_URL}/chat/completions',
            headers=headers,
            json=payload,
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_message = result['choices'][0]['message']['content'].strip()
            
            # æ¸…ç†å¯èƒ½å‡ºç°çš„æ ¼å¼æ ‡ç­¾
            ai_message = clean_response(ai_message)
            
            return jsonify({
                'success': True,
                'message': ai_message,
                'type': interaction_type
            })
        else:
            return jsonify({
                'success': False,
                'error': f'APIè°ƒç”¨å¤±è´¥: {response.status_code}',
                'details': response.text
            }), response.status_code
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        }), 504
        
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        }), 500
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@ai_dialogue_bp.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        'success': True,
        'service': 'AI Dialogue',
        'status': 'running',
        'api_configured': bool(VECTORAPI_KEY)
    })